{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "del sys\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from tesa.toolbox.parsers import standard_parser, add_annotations_arguments, add_task_arguments\n",
    "from tesa.database_creation.annotation_task import AnnotationTask\n",
    "from tesa.preprocess_annotations import filter_annotations\n",
    "from tesa.toolbox.utils import load_task\n",
    "from tesa.modeling.utils import format_context\n",
    "from os.path import join as path_join\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ap = standard_parser()\n",
    "add_annotations_arguments(ap)\n",
    "add_task_arguments(ap)\n",
    "args = ap.parse_args([\"--root\", \"..\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the annotations data (and first preprocessing step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing the modeling task...\n",
      "Computing the annotated queries...\n",
      "Initial length of queries: 0.\n",
      "Object loaded from ../results/annotation_task/annotations/v2_0/task/queries_short.pkl.\n",
      "Object loaded from ../results/annotation_task/annotations/v2_1/task/queries.pkl.\n",
      "Object loaded from ../results/annotation_task/annotations/v2_2/task/queries.pkl.\n",
      "Final length of queries: 61056.\n",
      "Done. Elapsed time: 1s.\n",
      "\n",
      "Computing the annotations...\n",
      "Initial length of annotations: 0.\n",
      "batch_00 loaded from annotations/v2_0/results/batch_00_complete.csv\n",
      "Correcting \"n this article, Nevada and Ohio are discussed. The two American states...\" to \" The two American states...\"\n",
      "Correcting \"In this article, California and Oregon are discussed. The two neighboring states...\" to \" The two neighboring states...\"\n",
      "Correcting \"In this article, California and Oregon are discussed. The two West Coast states...\" to \" The two West Coast states...\"\n",
      "batch_01 loaded from annotations/v2_0/results/batch_01_complete.csv\n",
      "Discarding \"The\"\n",
      "Discarding \"The four people involved in the Rafferty and Parker murder case\"\n",
      "Discarding \"The two people involved in the accusations against Mr. Brookins and Mr. Hernandez\"\n",
      "Discarding \"The Canadian and American politicians\"\n",
      "Correcting \"THE CHESS CHAMPIONS\" to \"The chess champions\"\n",
      "Correcting \"THE WHITE AND BLACK\" to \"The white and black\"\n",
      "Discarding \"The white and black\"\n",
      "Discarding \"The North and South America countries\"\n",
      "Discarding \"Both are politlca entities\"\n",
      "batch_02 loaded from annotations/v2_1/results/batch_02_complete.csv\n",
      "Discarding \"Both groups have a military wing\"\n",
      "Discarding \"The financial/media concern\"\n",
      "Discarding \"Both countries are in Western Asia\"\n",
      "Correcting \"FOOTBALL TEAM\" to \"Football team\"\n",
      "Discarding \"Na\"\n",
      "batch_03 loaded from annotations/v2_1/results/batch_03_complete.csv\n",
      "Discarding \"The convicted Hynix managers/directors\"\n",
      "Discarding \"The areas that include or are included by Eurasia\"\n",
      "Discarding \"Evo Morales and Hugo Salvatierra\"\n",
      "Discarding \"The politician and the organ builder\"\n",
      "batch_04 loaded from annotations/v2_2/results/batch_04_complete.csv\n",
      "Discarding \"The country and its capital city\"\n",
      "Discarding \"The major united states city and the state nearby\"\n",
      "Discarding \"The judge and the woman he sentenced to jail\"\n",
      "Discarding \"Are in European territory\"\n",
      "Discarding \"The states that have seen declining enrollment in Medicaid\"\n",
      "batch_05 loaded from annotations/v2_2/results/batch_05_complete.csv\n",
      "Discarding \"Former attorneys and politicians\"\n",
      "Discarding \"The director/choreographers\"\n",
      "Discarding \"The writer/directors\"\n",
      "Final length of annotations: 2100.\n",
      "Done. Elapsed time: 1s.\n",
      "\n",
      "Done. Elapsed time: 2s.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "annotation_task = AnnotationTask(silent=args.silent,\n",
    "                                     results_path=path_join(args.root, args.annotations_path),\n",
    "                                     years=None,\n",
    "                                     max_tuple_size=None,\n",
    "                                     short=None,\n",
    "                                     short_size=None,\n",
    "                                     random=None,\n",
    "                                     debug=None,\n",
    "                                     random_seed=None,\n",
    "                                     save=None,\n",
    "                                     corpus_path=None)\n",
    "\n",
    "annotation_task.process_task(exclude_pilot=args.exclude_pilot)\n",
    "\n",
    "queries = annotation_task.queries\n",
    "annotations = annotation_task.annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_data = []\n",
    "for id_, annotation_list in annotations.items():\n",
    "    data = dict()\n",
    "    \n",
    "    query = queries[id_]\n",
    "    data[\"entities_type\"] = query.entities_type_\n",
    "    data[\"entities\"] = query.entities\n",
    "    data[\"summaries\"] = query.summaries\n",
    "    data[\"urls\"] = query.urls\n",
    "    data[\"title\"] = query.title\n",
    "    data[\"date\"] = query.date\n",
    "    data[\"context\"] = query.context\n",
    "    data[\"context_type\"] = query.context_type_\n",
    "    \n",
    "    for i, annotation in enumerate(annotation_list):\n",
    "        if annotation.answers:\n",
    "            data[f\"answer_{i}\"] = annotation.answers\n",
    "            \n",
    "    global_data.append(data)\n",
    "    \n",
    "df = pd.DataFrame(global_data)[[\"entities_type\",\"entities\",\"answer_0\",\"answer_1\",\"answer_2\",\"title\",\"date\",\"urls\",\"summaries\",\"context_type\",\"context\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../results/publication/dataset.csv\", index=False, mode=\"w\")\n",
    "pickle.dump(global_data, open(\"../results/publication/dataset.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the modeling task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task loaded from ../results/modeling_task/context-dependent-same-type_50-25-25_rs24_bs4_cf-v0_tf-v0.pkl.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "task = load_task(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for split in [\"train\", \"valid\", \"test\"]:\n",
    "    loader = getattr(task, f\"{split}_loader\")\n",
    "    global_data = []\n",
    "    \n",
    "    for ranking_task in loader:\n",
    "        data = dict()\n",
    "        \n",
    "        first_input = ranking_task[0][0]\n",
    "        data[\"entities\"] = first_input[\"entities\"]\n",
    "        data[\"entities_type\"] = first_input[\"entities_type\"]\n",
    "        data[\"wiki_articles\"] = first_input[\"wiki_articles\"]\n",
    "        assert len(first_input[\"nyt_titles\"]) == 1\n",
    "        assert len(first_input[\"nyt_contexts\"]) == 1\n",
    "        data[\"nyt_title\"] = first_input[\"nyt_titles\"][0]\n",
    "        data[\"nyt_context\"] = first_input[\"nyt_contexts\"][0]\n",
    "        \n",
    "        candidates = []\n",
    "        labels = []\n",
    "        \n",
    "        for batch_inputs, batch_outputs in ranking_task:\n",
    "            candidates.extend(batch_inputs[\"choices\"])\n",
    "            labels.extend(list(batch_outputs.tolist()))\n",
    "            \n",
    "        data[\"candidates\"] = candidates\n",
    "        data[\"labels\"] = labels\n",
    "        \n",
    "        global_data.append(data)\n",
    "\n",
    "    df = pd.DataFrame(global_data)[[\"entities_type\",\"entities\",\"wiki_articles\",\"nyt_title\",\"nyt_context\",\"candidates\",\"labels\"]]\n",
    "    \n",
    "    df.to_csv(f\"../results/publication/ranking_task_{split}.csv\", index=False, mode=\"w\")\n",
    "    pickle.dump(global_data, open(f\"../results/publication/ranking_task_{split}.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
